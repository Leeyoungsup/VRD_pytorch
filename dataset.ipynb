{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21047/21047 [03:41<00:00, 95.07it/s] \n"
     ]
    }
   ],
   "source": [
    "bbox_list=glob('../../data/total/bbox/*.json')\n",
    "relation_list=[f.replace('/data/total/bbox', '/data/total/relation') for f in bbox_list]\n",
    "df = pd.DataFrame(columns=['image','bounding box','label',\"entity1\",\"entity2\",\"relation\",\"english\",\"korean\"])\n",
    "for i in tqdm(range(len(bbox_list))):\n",
    "    with open(bbox_list[i], 'r') as f:\n",
    "\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    image_name=json_data['images'][0]['file_name']\n",
    "    width_ratio=256/json_data['images'][0]['width']\n",
    "    height_ratio=256/json_data['images'][0]['height']\n",
    "    annotation_count=len(json_data['annotations'])\n",
    "    annotation_list=[]\n",
    "    label_list=[]\n",
    "    entity1_list=[]\n",
    "    entity2_list=[]\n",
    "    relation_list1=[]\n",
    "    english_list=[]\n",
    "    korean_list=[]\n",
    "    for j in range(annotation_count):\n",
    "        resize_list=[int(json_data['annotations'][j]['bbox'][0]*width_ratio),int(json_data['annotations'][j]['bbox'][1]*height_ratio),int(json_data['annotations'][j]['bbox'][2]*width_ratio),int(json_data['annotations'][j]['bbox'][3]*height_ratio)]\n",
    "        annotation_list.append(resize_list)\n",
    "        label_list.append(json_data['annotations'][j]['category_id'])\n",
    "\n",
    "    with open(relation_list[i], 'r', encoding='utf-8-sig') as f:\n",
    "\n",
    "        json_data = json.load(f)\n",
    "        \n",
    "    annotation_count=len(json_data['annotations'][0]['text'])    \n",
    "    for k in range(annotation_count):\n",
    "        entity1_list.append(json_data['annotations'][0]['text'][k]['entity1'])\n",
    "        entity2_list.append(json_data['annotations'][0]['text'][k]['entity2'])\n",
    "        relation_list1.append(json_data['annotations'][0]['text'][k]['relation'])\n",
    "        english_list.append(json_data['annotations'][0]['text'][k]['english'])\n",
    "        korean_list.append(json_data['annotations'][0]['text'][k]['korean'])\n",
    "        'image','bounding box','label',\"entity1\",\"entity2\",\"relation\",\"english\",\"korean\"\n",
    "    df.at[i,'image']=image_name\n",
    "    df.at[i,'bounding box']=annotation_list\n",
    "    df.at[i,'label']=label_list\n",
    "    df.at[i,\"entity1\"]=entity1_list\n",
    "    df.at[i,\"entity2\"]=entity2_list\n",
    "    df.at[i,\"relation\"]=relation_list1\n",
    "    df.at[i,\"english\"]=english_list\n",
    "    df.at[i,\"korean\"]=korean_list\n",
    "df.to_csv('../../data/total/total.csv', mode='w',encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 크기: 16837\n",
      "검증 세트 크기: 2105\n",
      "테스트 세트 크기: 2105\n"
     ]
    }
   ],
   "source": [
    "df_shuffled = df.sample(frac=1, random_state=42)  \n",
    "train_ratio = 0.8\n",
    "valid_ratio = 0.1\n",
    "train, valid, test = np.split(df_shuffled, [int(train_ratio*len(df_shuffled)), int((train_ratio+valid_ratio)*len(df_shuffled))])\n",
    "print(f\"학습 세트 크기: {len(train)}\")\n",
    "print(f\"검증 세트 크기: {len(valid)}\")\n",
    "print(f\"테스트 세트 크기: {len(test)}\")\n",
    "train.to_csv('../../data/dataset/train/label.csv', mode='w',encoding='cp949', index=False)\n",
    "test.to_csv('../../data/dataset/test/label.csv', mode='w',encoding='cp949', index=False)\n",
    "valid.to_csv('../../data/dataset/validation/label.csv', mode='w',encoding='cp949', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16837/16837 [28:20<00:00,  9.90it/s] \n",
      "100%|██████████| 2105/2105 [03:31<00:00,  9.95it/s]\n",
      "100%|██████████| 2105/2105 [03:10<00:00, 11.05it/s]\n"
     ]
    }
   ],
   "source": [
    "total_image_path='../../data/total/img/'\n",
    "image_list=list(train['image'])\n",
    "for i in tqdm(range(len(image_list))):\n",
    "    img=Image.open(total_image_path+image_list[i]).resize((256,256))\n",
    "    img.save('../../data/dataset/train/image/'+image_list[i])\n",
    "\n",
    "image_list=list(test['image'])\n",
    "for i in tqdm(range(len(image_list))):\n",
    "    img=Image.open(total_image_path+image_list[i]).resize((256,256))\n",
    "    img.save('../../data/dataset/test/image/'+image_list[i])\n",
    "\n",
    "image_list=list(valid['image'])\n",
    "for i in tqdm(range(len(image_list))):\n",
    "    img=Image.open(total_image_path+image_list[i]).resize((256,256))\n",
    "    img.save('../../data/dataset/validation/image/'+image_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16837/16837 [07:37<00:00, 36.82it/s]\n"
     ]
    }
   ],
   "source": [
    "df_count=len(train)\n",
    "bbox_count=0\n",
    "caption_count=0\n",
    "train=train.reset_index()\n",
    "bbox_df=pd.DataFrame(columns=['image','x1','y1','x2','y2','label'])\n",
    "caption_df=pd.DataFrame(columns=['image','english','korean'])\n",
    "for i in tqdm(range(df_count)):\n",
    "    anno_count=len(train.loc[i]['bounding box'])\n",
    "    for j in range(anno_count):\n",
    "        image_name=train.loc[i]['image']\n",
    "        bbox_df.at[bbox_count,'image']=image_name\n",
    "        bbox_df.at[bbox_count,'x1']=train.loc[i]['bounding box'][j][0]\n",
    "        bbox_df.at[bbox_count,'y1']=train.loc[i]['bounding box'][j][1]\n",
    "        bbox_df.at[bbox_count,'x2']=train.loc[i]['bounding box'][j][2]+train.loc[i]['bounding box'][j][0]\n",
    "        bbox_df.at[bbox_count,'y2']=train.loc[i]['bounding box'][j][0]+train.loc[i]['bounding box'][j][1]\n",
    "        bbox_df.at[bbox_count,'label']=train.loc[i]['bounding box'][j][0]+train.loc[i]['label'][j]\n",
    "        bbox_count+=1\n",
    "\n",
    "    cap_count=len(train.loc[i]['english'])\n",
    "    for j in range(cap_count):\n",
    "        image_name=train.loc[i]['image']\n",
    "        caption_df.at[caption_count,'image']=image_name\n",
    "        caption_df.at[caption_count,'english']=train.loc[i]['english'][j]\n",
    "        caption_df.at[caption_count,'korean']=train.loc[i]['korean'][j]\n",
    "        caption_count+=1\n",
    "\n",
    "bbox_df.to_csv('../../data/dataset/train/bbox_label.csv', mode='w',encoding='cp949', index=False)\n",
    "caption_df.to_csv('../../data/dataset/train/caption_label.csv', mode='w',encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2105/2105 [00:16<00:00, 125.83it/s]\n"
     ]
    }
   ],
   "source": [
    "df_count=len(test)\n",
    "bbox_count=0\n",
    "caption_count=0\n",
    "test=test.reset_index()\n",
    "bbox_df=pd.DataFrame(columns=['image','x1','y1','x2','y2','label'])\n",
    "caption_df=pd.DataFrame(columns=['image','english','korean'])\n",
    "for i in tqdm(range(df_count)):\n",
    "    anno_count=len(test.loc[i]['bounding box'])\n",
    "    for j in range(anno_count):\n",
    "        image_name=test.loc[i]['image']\n",
    "        bbox_df.at[bbox_count,'image']=image_name\n",
    "        bbox_df.at[bbox_count,'x1']=test.loc[i]['bounding box'][j][0]\n",
    "        bbox_df.at[bbox_count,'y1']=test.loc[i]['bounding box'][j][1]\n",
    "        bbox_df.at[bbox_count,'x2']=test.loc[i]['bounding box'][j][2]+test.loc[i]['bounding box'][j][0]\n",
    "        bbox_df.at[bbox_count,'y2']=test.loc[i]['bounding box'][j][0]+test.loc[i]['bounding box'][j][1]\n",
    "        bbox_df.at[bbox_count,'label']=test.loc[i]['bounding box'][j][0]+test.loc[i]['label'][j]\n",
    "        bbox_count+=1\n",
    "\n",
    "    cap_count=len(test.loc[i]['english'])\n",
    "    for j in range(cap_count):\n",
    "        image_name=test.loc[i]['image']\n",
    "        caption_df.at[caption_count,'image']=image_name\n",
    "        caption_df.at[caption_count,'english']=test.loc[i]['english'][j]\n",
    "        caption_df.at[caption_count,'korean']=test.loc[i]['korean'][j]\n",
    "        caption_count+=1\n",
    "\n",
    "bbox_df.to_csv('../../data/dataset/test/bbox_label.csv', mode='w',encoding='cp949', index=False)\n",
    "caption_df.to_csv('../../data/dataset/test/caption_label.csv', mode='w',encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2105/2105 [00:16<00:00, 124.39it/s]\n"
     ]
    }
   ],
   "source": [
    "df_count=len(valid)\n",
    "bbox_count=0\n",
    "caption_count=0\n",
    "valid=valid.reset_index()\n",
    "bbox_df=pd.DataFrame(columns=['image','x1','y1','x2','y2','label'])\n",
    "caption_df=pd.DataFrame(columns=['image','english','korean'])\n",
    "for i in tqdm(range(df_count)):\n",
    "    anno_count=len(valid.loc[i]['bounding box'])\n",
    "    for j in range(anno_count):\n",
    "        image_name=valid.loc[i]['image']\n",
    "        bbox_df.at[bbox_count,'image']=image_name\n",
    "        bbox_df.at[bbox_count,'x1']=valid.loc[i]['bounding box'][j][0]\n",
    "        bbox_df.at[bbox_count,'y1']=valid.loc[i]['bounding box'][j][1]\n",
    "        bbox_df.at[bbox_count,'x2']=valid.loc[i]['bounding box'][j][2]+valid.loc[i]['bounding box'][j][0]\n",
    "        bbox_df.at[bbox_count,'y2']=valid.loc[i]['bounding box'][j][0]+valid.loc[i]['bounding box'][j][1]\n",
    "        bbox_df.at[bbox_count,'label']=valid.loc[i]['bounding box'][j][0]+valid.loc[i]['label'][j]\n",
    "        bbox_count+=1\n",
    "\n",
    "    cap_count=len(valid.loc[i]['english'])\n",
    "    for j in range(cap_count):\n",
    "        image_name=valid.loc[i]['image']\n",
    "        caption_df.at[caption_count,'image']=image_name\n",
    "        caption_df.at[caption_count,'english']=valid.loc[i]['english'][j]\n",
    "        caption_df.at[caption_count,'korean']=valid.loc[i]['korean'][j]\n",
    "        caption_count+=1\n",
    "\n",
    "bbox_df.to_csv('../../data/dataset/validation/bbox_label.csv', mode='w',encoding='cp949', index=False)\n",
    "caption_df.to_csv('../../data/dataset/validation/caption_label.csv', mode='w',encoding='cp949', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
